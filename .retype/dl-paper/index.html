<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="turbo-cache-control" content="no-cache" data-turbo-track="reload" data-track-token="2.3.0.715268998224">

    <!-- See retype.com -->
    <meta name="generator" content="Retype 2.3.0">

    <!-- Primary Meta Tags -->
    <title>deep-learning-papers</title>
    <meta name="title" content="deep-learning-papers">
    <meta name="description" content="AlexNet: ImageNet Classification with Deep Convolutional Neural Networks ( note)" />

    <!-- Canonical -->
    <link rel="canonical" href="https://tech/dl-paper/" />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://tech/dl-paper/">
    <meta property="og:title" content="deep-learning-papers">
    <meta property="og:description" content="AlexNet: ImageNet Classification with Deep Convolutional Neural Networks ( note)">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://tech/dl-paper/">
    <meta property="twitter:title" content="deep-learning-papers">
    <meta property="twitter:description" content="AlexNet: ImageNet Classification with Deep Convolutional Neural Networks ( note)">

    <script>(function () { var el = document.documentElement, m = localStorage.getItem("doc_theme"), wm = window.matchMedia; if (m === "dark" || (!m && wm && wm("(prefers-color-scheme: dark)").matches)) { el.classList.add("dark") } else { el.classList.remove("dark") } })();</script>

    <link href="../resources/css/retype.css?v=2.3.0.715268998224" rel="stylesheet" />

    <script type="text/javascript" src="../resources/js/config.js?v=2.3.0.715268998224" data-turbo-eval="false" defer></script>
    <script type="text/javascript" src="../resources/js/retype.js?v=2.3.0" data-turbo-eval="false" defer></script>
    <script id="lunr-js" type="text/javascript" src="../resources/js/lunr.js?v=2.3.0.715268998224" data-turbo-eval="false" defer></script>
</head>
<body>
    <div id="docs-app" class="relative text-base antialiased text-gray-700 bg-white font-body dark:bg-dark-850 dark:text-dark-300">
        <div class="absolute bottom-0 left-0 bg-gray-100 dark:bg-dark-800" style="top: 5rem; right: 50%"></div>
    
        <header id="docs-site-header" class="sticky top-0 z-30 flex w-full h-16 bg-white border-b border-gray-200 md:h-20 dark:bg-dark-850 dark:border-dark-650">
            <div class="container relative flex items-center justify-between grow pr-6 md:justify-start">
                <!-- Mobile menu button skeleton -->
                <button v-cloak class="skeleton docs-mobile-menu-button flex items-center justify-center shrink-0 overflow-hidden dark:text-white focus:outline-none rounded-full w-10 h-10 ml-3.5 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" class="mb-px shrink-0" width="24" height="24" viewBox="0 0 24 24" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor"><path d="M2 4h20v2H2zM2 11h20v2H2zM2 18h20v2H2z"></path></g></svg></button>
                <div v-cloak id="docs-sidebar-toggle"></div>
        
                <!-- Logo -->
                <div class="flex items-center justify-between h-full py-2 md:w-75">
                    <div class="flex items-center px-2 md:px-6">
                        <a id="docs-site-logo" href="../" class="flex items-center leading-snug text-2xl">
                            <span class="w-10 mr-2 grow-0 shrink-0 overflow-hidden">
                                <img class="max-h-10 dark:hidden md:inline-block" src="../static/saintly-logo.svg">
                                <img class="max-h-10 hidden dark:inline-block" src="../static/saintly-logo-dark.svg">
                            </span>
                            <span class="dark:text-white font-semibold line-clamp-1 md:line-clamp-2">S.KYUHWN</span>
                        </a>
                    </div>
        
                    <span class="hidden h-8 border-r md:inline-block dark:border-dark-650"></span>
                </div>
        
                <div class="flex justify-between md:grow">
                    <!-- Top Nav -->
                    <nav class="hidden md:flex">
                        <ul class="flex flex-col mb-4 md:pl-16 md:mb-0 md:flex-row md:items-center">
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="../">Home</a>
                            </li>
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://github.com/underthelights/">GitHub</a>
                            </li>
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://drive.google.com/file/d/1lcEg4fXJvTQlCKW5mWai_ej8NZGg21yT/view">Resume</a>
                            </li>
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://www.linkedin.com/in/kyuhwan-shim/">Linkedin</a>
                            </li>
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://underthelights.github.io">GitBlog</a>
                            </li>
        
                        </ul>
                    </nav>
        
                    <!-- Header Right Skeleton -->
                    <div v-cloak class="flex justify-end grow skeleton">
        
                        <!-- Search input mock -->
                        <div class="relative hidden w-40 lg:block lg:max-w-sm lg:ml-auto">
                            <div class="absolute flex items-center justify-center h-full pl-3 dark:text-dark-300">
                                <svg xmlns="http://www.w3.org/2000/svg" class="icon-base" width="16" height="16" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation"  style="margin-bottom: 1px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                            </div>
        
                            <input class="w-full h-10 transition-colors duration-200 ease-in bg-gray-200 border border-transparent rounded md:text-sm hover:bg-white hover:border-gray-300 focus:outline-none focus:bg-white focus:border-gray-500 dark:bg-dark-600 dark:border-dark-600 placeholder-gray-400 dark:placeholder-dark-400"
                            style="padding: 0.625rem 0.75rem 0.625rem 2rem" type="text" placeholder="Search" />
                        </div>
        
                        <!-- Mobile search button mock -->
                        <div class="flex items-center justify-center w-10 h-10 lg:hidden">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="20" height="20" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation"  style="margin-bottom: 0px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                        </div>
        
                        <!-- Dark mode switch placehokder -->
                        <div class="w-10 h-10 lg:ml-2"></div>
        
                        <!-- History button mock -->
                        <div class="flex items-center justify-center w-10 h-10" style="margin-right: -0.625rem;">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="22" height="22" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation"  style="margin-bottom: 0px;"><g fill="currentColor" ><g ><path d="M12.01 6.01c-.55 0-1 .45-1 1V12a1 1 0 00.4.8l3 2.22a.985.985 0 001.39-.2.996.996 0 00-.21-1.4l-2.6-1.92V7.01c.02-.55-.43-1-.98-1z"></path><path d="M12.01 1.91c-5.33 0-9.69 4.16-10.05 9.4l-.29-.26a.997.997 0 10-1.34 1.48l1.97 1.79c.19.17.43.26.67.26s.48-.09.67-.26l1.97-1.79a.997.997 0 10-1.34-1.48l-.31.28c.34-4.14 3.82-7.41 8.05-7.41 4.46 0 8.08 3.63 8.08 8.09s-3.63 8.08-8.08 8.08c-2.18 0-4.22-.85-5.75-2.4a.996.996 0 10-1.42 1.4 10.02 10.02 0 007.17 2.99c5.56 0 10.08-4.52 10.08-10.08.01-5.56-4.52-10.09-10.08-10.09z"></path></g></g></svg>
                        </div>
                    </div>
        
                    <div v-cloak class="flex justify-end grow">
                        <div id="docs-mobile-search-button"></div>
                        <doc-search-desktop></doc-search-desktop>
        
                        <doc-theme-switch class="lg:ml-2"></doc-theme-switch>
                        <doc-history></doc-history>
                    </div>
                </div>
            </div>
        </header>
    
        <div class="container relative flex bg-white">
            <!-- Sidebar Skeleton -->
            <div v-cloak class="fixed flex flex-col shrink-0 duration-300 ease-in-out bg-gray-100 border-gray-200 sidebar top-20 w-75 border-r h-screen md:sticky transition-transform skeleton dark:bg-dark-800 dark:border-dark-650">
            
                <!-- Render this div, if config.showSidebarFilter is `true` -->
                <div class="flex items-center h-16 px-6">
                    <input class="w-full h-8 px-3 py-2 transition-colors duration-200 ease-linear bg-white border border-gray-200 rounded shadow-none text-sm focus:outline-none focus:border-gray-600 dark:bg-dark-600 dark:border-dark-600" type="text" placeholder="Filter" />
                </div>
            
                <div class="pl-6 mb-4 mt-1">
                    <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                </div>
            
                <div class="shrink-0 mt-auto bg-transparent dark:border-dark-650">
                    <a class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                        <span class="text-xs whitespace-nowrap">Powered by</span>
                        <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                    </a>
                </div>
            </div>
            
            <!-- Sidebar component -->
            <doc-sidebar v-cloak>
                <template #sidebar-footer>
                    <div class="shrink-0 mt-auto border-t md:bg-transparent md:border-none dark:border-dark-650">
            
                        <div class="py-3 px-6 md:hidden border-b dark:border-dark-650">
                            <nav>
                                <ul class="flex flex-wrap justify-center items-center">
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="../">Home</a>
                                    </li>
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://github.com/underthelights/">GitHub</a>
                                    </li>
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://drive.google.com/file/d/1lcEg4fXJvTQlCKW5mWai_ej8NZGg21yT/view">Resume</a>
                                    </li>
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://www.linkedin.com/in/kyuhwan-shim/">Linkedin</a>
                                    </li>
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://underthelights.github.io">GitBlog</a>
                                    </li>
            
                                </ul>
                            </nav>
                        </div>
            
                        <a class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                            <span class="text-xs whitespace-nowrap">Powered by</span>
                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                        </a>
                    </div>
                </template>
            </doc-sidebar>
    
            <div class="grow min-w-0 dark:bg-dark-850">
                <!-- Render "toolbar" template here on api pages --><!-- Render page content -->
                <div class="flex">
                    <div class="grow min-w-0 px-6 md:px-16">
                        <main class="relative pt-6 pb-16">
                            <div class="docs-markdown" id="docs-content">
                                <!-- Rendered if sidebar right is enabled -->
                                <div id="docs-sidebar-right-toggle"></div>
                
                                <!-- Page content  -->
<doc-anchor-target id="deep-learning-papers" class="break-words">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#deep-learning-papers">#</doc-anchor-trigger>
        <span>deep-learning-papers</span>
    </h1>
</doc-anchor-target>
<doc-anchor-target id="computer-vision">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#computer-vision">#</doc-anchor-trigger>
        <span>Computer Vision</span>
    </h2>
</doc-anchor-target>
<doc-anchor-target id="cnn-architecture">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#cnn-architecture">#</doc-anchor-trigger>
        <span>CNN Architecture</span>
    </h3>
</doc-anchor-target>
<ul>
<li>AlexNet: ImageNet Classification with Deep Convolutional Neural Networks (<a href="https://drive.google.com/open?id=1oxzo2ZulvusLn_ETVK5mTPlgqPJLs9HA">note</a>)</li>
<li>ZFNet (DeconvNet): Visualizing and Understanding Convolutional Networks (<a href="https://drive.google.com/open?id=1bzkoKVxLALaD6ZWQh5-vP9qOodMdIwi0">note</a>, code)</li>
<li>NIN: Network in Network</li>
<li>VggNet: Very Deep Convolutional Networks for Large-Scale Image Recognition</li>
<li>GoogLeNet: Going Deeper with Convolutions</li>
<li>ResNet:
<ul>
<li>ResNet-v1: Deep Residual Learning for Image Recognition (<a href="https://drive.google.com/open?id=1Ahws2bBE_YSjvNcxsF9tnwRCv3HfaVhr">note</a>)</li>
<li>ResNet-v2: Identity Mappings in Deep Residual Networks</li>
<li>Wide Residual Networks (<a href="https://drive.google.com/open?id=14eQSeymwXgS7JvBbAkOnudAm6MFnJify">note</a>, code)</li>
</ul>
</li>
<li>InceptionNet:
<ul>
<li>Inception-v1: GoogLeNet</li>
<li>Inception-v2, v3: Rethinking the Inception Architecture for Computer Vision (<a href="https://drive.google.com/open?id=1SVOpf9aElrAGCZHlX7NvYL8pbehXpw8i">note</a>, code)</li>
<li>Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</li>
</ul>
</li>
<li>DenseNet:</li>
<li>NASNet: Learning Transferable Architectures for Scalable Image Recognition (<a href="https://drive.google.com/open?id=1o1SfbVIgEhRWGQG_mPpxKoCDyWtNoifJ">note</a>, code)</li>
<li>EfficientNet:(<a href="https://drive.google.com/open?id=1LtdSId0HTpM8_O4k4WFrzHz4ldPf7dTu">note</a>)</li>
</ul>
<doc-anchor-target id="visualizing-cnns">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#visualizing-cnns">#</doc-anchor-trigger>
        <span><a href="doc/visualizing_cnn/">Visualizing CNNs</a></span>
    </h3>
</doc-anchor-target>
<ul>
<li>DeconvNet</li>
<li>BP: Deep inside convolutional networks: Visualising image classification models and saliency maps (<a href="https://drive.google.com/open?id=1IBP1uMr08hBp3bKjvyNnwFMu0S8ORGcs">note</a>)</li>
<li>Guided-BP (DeconvNet+BP): Striving for simplicity: The all convolutional net (<a href="https://drive.google.com/open?id=1KUq5-h_xVmjd4FudGDeBUfPV9vBMHV68">note</a>, code)</li>
<li>Understanding Neural Networks Through Deep Visualization</li>
</ul>
<doc-anchor-target id="weakly-supervised-localization">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#weakly-supervised-localization">#</doc-anchor-trigger>
        <span><a href="doc/cam/">Weakly Supervised Localization</a></span>
    </h3>
</doc-anchor-target>
<ul>
<li>From Image-level to Pixel-level Labeling with Convolutional Networks (2015)</li>
<li>GMP-CAM: Is object localization for free? - Weakly-supervised learning with convolutional neural networks (2015) (<a href="https://drive.google.com/open?id=1Xpnhq0snjkPMsxKLpmhLOpoZgfFlL9H3">note</a>, code)</li>
<li>GAP-CAM: Learning Deep Features for Discriminative Localization (2016) (<a href="https://drive.google.com/open?id=1lrkE07E3bnLscAnScwq0OIO3AaRHrqnb">note</a>, code)</li>
<li>c-MWP: Top-down Neural Attention by Excitation Backprop</li>
<li>Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization (2017) (<a href="https://drive.google.com/open?id=10obbO7F2igia6gCcc9IqxATzOxdoPl7L">note</a>, code)</li>
</ul>
<doc-anchor-target id="object-detection">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#object-detection">#</doc-anchor-trigger>
        <span><a href="doc/detection/">Object Detection</a></span>
    </h3>
</doc-anchor-target>
<ul>
<li>OverFeat - Integrated Recognition, Localization and Detection using Convolutional Networks (<a href="https://drive.google.com/open?id=1O3j-ag0pPRbRjG4ovWmxnZIwhUJ0twvK">note</a>, code)</li>
</ul>
<doc-anchor-target id="semantic-segmentation">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#semantic-segmentation">#</doc-anchor-trigger>
        <span><a href="doc/semantic_segmentation/">Semantic Segmentation</a></span>
    </h3>
</doc-anchor-target>
<ul>
<li>FCN_V1 (2014)에서 직접적인 영향을 받은 모델들:
<ul>
<li>FCN + max-pooling indices를 사용: SegNet V2 (2015) (<a href="https://drive.google.com/open?id=1CDNkW-3LKVDjGAyPCgj8fOz78pMY0Pd7">note</a>)</li>
<li>FCN 개선: Fully Convolutional Networks for Semantic Segmentation (FCN_V2, 2016) (<a href="https://drive.google.com/open?id=1Kr2-ZdiqKmsgXP2ofaUZm_PT5UbbTyDN">note</a>, <a href="https://github.com/bt22dr/CarND-Semantic-Segmentation/blob/master/main.py">code</a>)</li>
<li>FCN + atrous convolution과 CRF를 사용: DeepLap V2 (2016)</li>
<li>FCN + Dilated convolutions 사용: Multi-Scale Context Aggregation by Dilated Convolutions (2015)</li>
<li>FCN + Multi-scale: Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture (2015)</li>
<li>FCN + global context 반영 위해 global pooling 사용: ParseNet (2015)</li>
<li>FCN + 모든 레이어에서 skip 사용: U-Net (2015) (<a href="https://drive.google.com/open?id=1Up8PiwA79J8R3ScjgYTmLzt8pYYa83EN">note</a>)</li>
</ul>
</li>
<li>PSPNet (2016) (<a href="https://drive.google.com/open?id=1xPu7Z-0jWepxb1av9fG2Py72Yz0enWym">note</a>)</li>
<li>DeepLabv3+ (2018) (<a href="https://drive.google.com/open?id=1YFUdcwKzIrTzfmL6o94y01tDXsZ2n6vc">note</a>)</li>
<li>EncNet (2018)</li>
<li>FastFCN (2019)</li>
<li>Instance Segmentation
<ul>
<li>DeepMask</li>
<li>SharpMask</li>
<li>Mask R-CNN (2017) (<a href="https://drive.google.com/open?id=1kFVOdctJTcWYkflfCM1Ys-J7Fo8COC6R">note</a>)</li>
</ul>
</li>
<li>3D / Point Cloud
<ul>
<li>PointNet (2017)</li>
<li>SGPN (2017)</li>
</ul>
</li>
<li>Weakly-supervised Segmentation</li>
</ul>
<doc-anchor-target id="style-transfer">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#style-transfer">#</doc-anchor-trigger>
        <span><a href="doc/style_transfer/">Style Transfer</a></span>
    </h3>
</doc-anchor-target>
<ul>
<li><del>A Neural Algorithm of Artistic Style (2015)</del></li>
<li>Image Style Transfer Using Convolutional Neural Networks (2016)</li>
<li>Perceptual Losses for Real-Time Style Transfer and Super-Resolution (2016)</li>
<li>Instance Normalization:
<ul>
<li>Instance Normalization: The Missing Ingredient for Fast Stylization (2016)</li>
<li>Improved Texture Networks: Maximizing Quality and Diversity in Feed-forward Stylization and Texture Synthesis (2017)</li>
</ul>
</li>
</ul>
<doc-anchor-target id="siamese-triplet-network">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#siamese-triplet-network">#</doc-anchor-trigger>
        <span>Siamese, Triplet Network</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Triplet Network
<ul>
<li>FaceNet: A Unified Embedding for Face Recognition and Clustering (<a href="https://drive.google.com/open?id=1E9ZGncIvpJoPK5_mSq5J-Mn33r2_xAqj">note</a>, code)</li>
<li>Learning Fine-grained Image Similarity with Deep Ranking (<a href="https://drive.google.com/open?id=1BrjRlzB139v5nmCgdLruJGn1drmBb33m">note</a>, code)</li>
</ul>
</li>
<li>Siamese Network</li>
</ul>
<doc-anchor-target id="mobile">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#mobile">#</doc-anchor-trigger>
        <span>Mobile</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Shufflenet: An extremely efficient convolutional neural network for mobile devices</li>
<li>Mobilenets: Efficient convolutional neural networks for mobile vision applications</li>
</ul>
<doc-anchor-target id="etc">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#etc">#</doc-anchor-trigger>
        <span><a href="./doc/etc/md">Etc.</a></span>
    </h3>
</doc-anchor-target>
<ul>
<li>A guide to convolution arithmetic for deep learning (<a href="https://drive.google.com/open?id=1zGGzI4qc49u5zV0jFSkzD8xDMY0OalN1">note</a>)</li>
</ul>
<doc-anchor-target id="generative-models">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#generative-models">#</doc-anchor-trigger>
        <span><a href="doc/gan/">Generative Models</a></span>
    </h2>
</doc-anchor-target>
<doc-anchor-target id="models">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#models">#</doc-anchor-trigger>
        <span>Models</span>
    </h3>
</doc-anchor-target>
<doc-anchor-target id="autoregressive-models">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#autoregressive-models">#</doc-anchor-trigger>
        <span>Autoregressive Models</span>
    </h4>
</doc-anchor-target>
<ul>
<li>NADE (2011)</li>
<li>RNADE (2013)</li>
<li>MADE (2015)</li>
<li>PixelRNN 계열
<ul>
<li>PixelCNN (2016): (<a href="https://drive.google.com/open?id=1G_iIjf9dIWqge21sxrpcqK2L76PY8elN">note</a>, <a href="code/pixelcnn_mnist.ipynb">code1(mnist)</a>, <a href="code/pixelcnn_fashionmnist.ipynb">code2(fashion_mnist)</a>)</li>
<li>WaveNet (2016) (<a href="https://drive.google.com/open?id=1qnNQS_aFuPly8MVO7kSPytPAgf-KifbC">note</a>, <a href="code/wavenet.ipynb">code</a>)</li>
<li>VQ-VAE: Neural Discrete Representation Learning</li>
</ul>
</li>
</ul>
<doc-anchor-target id="variational-autoencoders">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#variational-autoencoders">#</doc-anchor-trigger>
        <span>Variational Autoencoders</span>
    </h4>
</doc-anchor-target>
<ul>
<li>VAE (<a href="https://github.com/bt22dr/deep-learning-papers/blob/master/doc/gan.md#auto-encoding-variational-bayes">note</a>, <a href="code/vae.ipynb">code1(mnist)</a>, <a href="code/vae_fashion_mnist.ipynb">code2(fashion_mnist)</a>)</li>
<li>Conditional VAE (<a href="https://drive.google.com/open?id=1f9fGvvtj-FdPJRwtw7PFLW0ysAu-U_2O">note</a>, <a href="code/conditional_vae_fashion_mnist.ipynb">code</a>)</li>
<li>VAE-GAN: Autoencoding beyond pixels using a learned similarity metric</li>
</ul>
<doc-anchor-target id="normalizing-flow-models">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#normalizing-flow-models">#</doc-anchor-trigger>
        <span>Normalizing Flow Models</span>
    </h4>
</doc-anchor-target>
<ul>
<li>NICE (2014) (<a href="https://drive.google.com/open?id=1Bz8i8lASNr8SS6vBraDOyOPTJY61q2aG">note</a>)</li>
<li>Variational Inference with Normalizing Flows (2015) (<a href="https://drive.google.com/drive/folders/1-kqyXOvnuw7aeOwbAfKO2OWUkFdv3AmR">code</a>)</li>
<li>IAF (2016)</li>
<li>MAF (2017)</li>
<li>Glow (2018)</li>
</ul>
<doc-anchor-target id="gans">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#gans">#</doc-anchor-trigger>
        <span>GANs</span>
    </h4>
</doc-anchor-target>
<ul>
<li>GAN: Generative Adversarial Networks (<a href="https://drive.google.com/open?id=1gymav6NryH-0AJqJ7hRt6SzFLrX8bCIn">note</a>, <a href="code/gan.ipynb">code1(mnist)</a>, <a href="code/gan_fashion_mnist.ipynb">code2(fashion_mnist)</a>)</li>
<li>DCGAN (<a href="https://drive.google.com/open?id=1IWeM32QDq97mQ8BdA-rWa58AiRqWTepG">note</a>, <a href="code/dcgan_mnist.ipynb">code1</a>, <a href="code/dcgan_celeba.ipynb">code2</a>)</li>
<li>WGAN 계열:
<ul>
<li>WGAN: Wasserstein GAN (<a href="https://drive.google.com/open?id=1CnfvynSKj9apRZBLjzWB--QJ69PKj2wy">note(진행중)</a>, <a href="code/wgan.ipynb">code</a>)</li>
<li>WGAN_GP: Improved Training of Wasserstein GANs</li>
<li>CT-GAN: Improving the Improved Training of Wasserstein GANs</li>
</ul>
</li>
<li>infoGAN</li>
<li>Improved GAN:</li>
<li>SNGAN: Spectral Normalization for Generative Adversarial Networks (<a href="https://drive.google.com/open?id=1qJmWsSKPQ2yXQDh68KcZsdEHeAkRvcgZ">note(진행중)</a>, <a href="code/sngan_fashion_mnist.ipynb">code</a>)</li>
<li>SAGAN:</li>
<li>CoGAN: Coupled Generative Adversarial Networks (note, code)</li>
</ul>
<doc-anchor-target id="image-generation">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#image-generation">#</doc-anchor-trigger>
        <span><a href="doc/img2img_translation/">Image generation</a></span>
    </h3>
</doc-anchor-target>
<doc-anchor-target id="image-to-image">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#image-to-image">#</doc-anchor-trigger>
        <span>image-to-image</span>
    </h4>
</doc-anchor-target>
<ul>
<li>cGAN: Conditional Generative Adversarial Nets (2014) (<a href="https://drive.google.com/open?id=1z1flvsqORItbCTZEGuFBQmubvNnAGzs-">note</a>, <a href="code/cgan.ipynb">code</a>)</li>
<li>(내맘대로)pix2pix 계열:
<ul>
<li>pix2pix: Image-to-Image Translation with Conditional Adversarial Networks (2016) (<a href="https://drive.google.com/open?id=1GYphdvvfuyb-YKDd_ItvwCLkNDqtY_5F">note</a>)</li>
<li><del>pix2pixHD</del></li>
<li>CycleGAN:</li>
<li>BicycleGAN</li>
<li>vid2vid: Video-to-Video Synthesis</li>
<li>SPADE: Semantic Image Synthesis with Spatially-Adaptive Normalization (2019) (<a href="https://drive.google.com/open?id=1CtbIRJ7wi7-wH9h7zQiClcHeqcfdoHEU">note</a>)</li>
</ul>
</li>
<li>StarGAN:</li>
<li>PGGAN:</li>
<li><del>UNIT/MUNIT</del></li>
<li><del>iGAN</del></li>
<li>StyleGAN:</li>
</ul>
<doc-anchor-target id="text-to-image">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#text-to-image">#</doc-anchor-trigger>
        <span>text-to-image</span>
    </h4>
</doc-anchor-target>
<ul>
<li>Generative adversarial text to image synthesis</li>
<li>StackGAN</li>
<li>AttnGAN</li>
</ul>
<doc-anchor-target id="sequence-generation">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#sequence-generation">#</doc-anchor-trigger>
        <span>Sequence generation</span>
    </h3>
</doc-anchor-target>
<ul>
<li>WaveGAN: (<a href="https://drive.google.com/open?id=1zd4pw884TztzisixmJSJDYTXcdXZSbdo">note</a>, code)</li>
<li>SeqGAN:</li>
</ul>
<doc-anchor-target id="evaluation">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#evaluation">#</doc-anchor-trigger>
        <span>Evaluation</span>
    </h3>
</doc-anchor-target>
<ul>
<li>A note on the evaluation of generative models</li>
<li>A Note on the Inception Score</li>
</ul>
<doc-anchor-target id="cs236-deep-generative-models">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#cs236-deep-generative-models">#</doc-anchor-trigger>
        <span>CS236 (Deep Generative Models)</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Introduction and Background (<a href="https://drive.google.com/open?id=1y9-nkh9OhxAuRP009FsZUDB8hjb3b9iG">slide 1</a>, <a href="https://drive.google.com/open?id=1Kmd7lnZJTw-mgwcTR91nWRVdxQ9Ot5X7">slide 2</a>)</li>
<li>Autoregressive Models (<a href="https://drive.google.com/open?id=18l4h4iQ_lAROCOlKf44VGk-Q7DEvtBp6">slide 3</a>, <a href="https://drive.google.com/open?id=1IQ5LdSyO9UXi3yjh9c_m7AhK0jmIqQNF">slide 4</a>)</li>
<li>Variational Autoencoders</li>
<li>Normalizing Flow Models</li>
<li>Generative Adversarial Networks</li>
<li>Energy-based models</li>
</ul>
<doc-anchor-target id="nlp">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#nlp">#</doc-anchor-trigger>
        <span>NLP</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Recent Trends in Deep Learning Based Natural Language Processing (<a href="https://drive.google.com/open?id=12dosro89x1wy3wXUfJ26oa3_2hU_S6n6">note</a>)</li>
</ul>
<doc-anchor-target id="rnn-architecture">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#rnn-architecture">#</doc-anchor-trigger>
        <span>RNN Architecture</span>
    </h3>
</doc-anchor-target>
<ul>
<li>Seq2Seq
<ul>
<li>Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation (2014)</li>
<li>Sequence to Sequence Learning with Neural Networks (2014) (<a href="https://drive.google.com/open?id=1crgnXU-3JClMsF1ZYLr8bxxWkSZjcTEZ">note</a>, code)</li>
<li>A Neural Conversational Model</li>
</ul>
</li>
<li>Attention
<ul>
<li>(Luong) Effective Approaches to Attention-based Neural Machine Translation (2015)</li>
<li>(Bahdanau) Neural Machine Translation by Jointly Learning to Align and Translate (2014) (<a href="https://drive.google.com/open?id=1YJLljd9YbOzW5mADOtAT7V3imfMBi3Fg">note</a>, code)</li>
<li>Transformer: Attention Is All You Need (2017)</li>
</ul>
</li>
<li>Memory Network
<ul>
<li>Memory Networks (2014)</li>
<li>End-To-End Memory Networks (2015)</li>
</ul>
</li>
<li>Residual Connection
<ul>
<li>Deep Recurrent Models with Fast-Forward Connections for NeuralMachine Translation (2016)</li>
<li>Google&#x27;s Neural MachineTranslation: Bridging the Gap between Human and Machine Translation (2016)</li>
</ul>
</li>
<li>CNN
<ul>
<li>Convolutional Neural Networks for Sentence Classification (2014)</li>
<li>ByteNet: Neural Machine Translation in Linear Time (2017)</li>
<li>Depthwise Separable Convolutions for Neural Machine Translation (2017)</li>
<li>SliceNet: Convolutional Sequence to Sequence Learning (2017)</li>
</ul>
</li>
</ul>
<doc-anchor-target id="word-embedding">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#word-embedding">#</doc-anchor-trigger>
        <span>Word Embedding</span>
    </h3>
</doc-anchor-target>
<doc-anchor-target id="multimodal-learning">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#multimodal-learning">#</doc-anchor-trigger>
        <span>Multimodal Learning</span>
    </h2>
</doc-anchor-target>
<ul>
<li>DeVise - A Deep Visual-Semantic Embedding Model: (<a href="https://drive.google.com/open?id=19gr2FsgvfUAHHA4E25UFJAFmFSUD_L4k">note</a>)</li>
<li>Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models: (<a href="https://drive.google.com/open?id=1qytxJgLsZvlbazeXTfExqPA-2rUX1irB">note</a>)</li>
<li>Show and Tell: (<a href="https://drive.google.com/open?id=1fZJ7jopShsepyderJ03ivzoiGqMUOGl3">note</a>)</li>
<li>Show, Attend and Tell: (<a href="https://drive.google.com/open?id=1COSvkFUWxuotzicGFAlLbl5l_iRrsTtG">note</a>)</li>
<li>Multimodal Machine Learning: A Survey and Taxonomy: (<a href="https://drive.google.com/open?id=1qibjIoD5z6HjC_G6ICixpA_G0-A5P8t5">note</a>)</li>
</ul>
<doc-anchor-target id="etc-optimization-normalization-applications">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#etc-optimization-normalization-applications">#</doc-anchor-trigger>
        <span><a href="doc/etc/">Etc.</a> (Optimization, Normalization, Applications)</span>
    </h2>
</doc-anchor-target>
<ul>
<li>An overview of gradient descent optimization algorithms (<a href="https://drive.google.com/open?id=1eSNr4zQBKbQQRpxDl06AWEwAU5qysTo_">note</a>)</li>
<li>Dropout:</li>
<li>Batch Normalization: (<a href="https://drive.google.com/open?id=1rSM2Q510EjEZ3J6YpWH_ZwPiUS2JHQTp">pdf+memo</a>, code)</li>
<li>How Does Batch Normalization Help Optimization?</li>
<li>Spectral Norm Regularization for Improving the Generalizability of Deep Learning (<a href="https://drive.google.com/open?id=1_Th_cpo5rgTyQqi3085To_YgyNCmwlzL">note(진행중)</a>, code)</li>
<li>Wide &amp; Deep Learning for Recommender Systems</li>
<li>Xavier Initialization - Understanding the difficulty of training deep feedforward neural networks</li>
<li>PReLU, He Initialization - Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</li>
</ul>
<doc-anchor-target id="drug-discovery">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#drug-discovery">#</doc-anchor-trigger>
        <span><a href="doc/medical/">Drug Discovery</a></span>
    </h2>
</doc-anchor-target>

                                
                                <!-- Required only on API pages -->
                                <doc-toolbar-member-filter-no-results />
                            </div>
                            <footer class="clear-both">
                            
                                <nav class="flex mt-14">
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 h-full flex items-center break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-l-lg transition-colors duration-150 relative hover:z-5" href="../biology-3-hyper-by-ryu/">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mr-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19 11H7.41l5.29-5.29a.996.996 0 10-1.41-1.41l-7 7a1 1 0 000 1.42l7 7a1.024 1.024 0 001.42-.01.996.996 0 000-1.41L7.41 13H19c.55 0 1-.45 1-1s-.45-1-1-1z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                            <span>
                                                <span class="block text-xs font-normal text-gray-400 dark:text-dark-400">Previous</span>
                                                <span class="block mt-1">2020 06 01 biologyhyper</span>
                                            </span>
                                        </a>
                                    </div>
                            
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 -mx-px h-full flex items-center justify-end break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-r-lg transition-colors duration-150 relative hover:z-5" href="../dl-paper/doc/medical/">
                                            <span>
                                                <span class="block text-xs font-normal text-right text-gray-400 dark:text-dark-400">Next</span>
                                                <span class="block mt-1">Drug Discovery</span>
                                            </span>
                                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19.92 12.38a1 1 0 00-.22-1.09l-7-7a.996.996 0 10-1.41 1.41l5.3 5.3H5c-.55 0-1 .45-1 1s.45 1 1 1h11.59l-5.29 5.29a.996.996 0 000 1.41c.19.2.44.3.7.3s.51-.1.71-.29l7-7c.09-.09.16-.21.21-.33z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                        </a>
                                    </div>
                                </nav>
                            </footer>
                        </main>
                
                        <div class="border-t dark:border-dark-650 pt-6 mb-8">
                            <footer class="flex flex-wrap items-center justify-between">
                                <div>
                                    <ul class="flex flex-wrap items-center text-sm">
                                    </ul>
                                </div>
                                <div class="docs-copyright py-2 text-gray-500 dark:text-dark-350 text-sm leading-relaxed"><p>© Copyright 2020 - 2022 KyuHwan Shim, All rights reserved.</p></div>
                            </footer>
                        </div>
                    </div>
                
                    <!-- Rendered if sidebar right is enabled -->
                    <!-- Sidebar right skeleton-->
                    <div v-cloak class="fixed top-0 bottom-0 right-0 translate-x-full bg-white border-gray-200 lg:sticky lg:border-l lg:shrink-0 lg:pt-6 lg:transform-none sm:w-1/2 lg:w-64 lg:z-0 md:w-104 sidebar-right skeleton dark:bg-dark-850 dark:border-dark-650">
                        <div class="pl-5">
                            <div class="w-32 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                            <div class="w-48 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                            <div class="w-40 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                        </div>
                    </div>
                
                    <!-- User should be able to hide sidebar right -->
                    <doc-sidebar-right v-cloak></doc-sidebar-right>
                </div>

            </div>
        </div>
    
        <doc-search-mobile></doc-search-mobile>
        <doc-back-to-top></doc-back-to-top>
    </div>


    <div id="docs-overlay-target"></div>

    <script>window.__DOCS__ = { "title": "deep-learning-papers", level: 1, icon: "file", hasPrism: false, hasMermaid: false, hasMath: false }</script>
</body>
</html>
