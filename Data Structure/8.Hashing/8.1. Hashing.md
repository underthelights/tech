## Hashing (Chapter 8)

### Introduction

- In this course, we have looked at many different abstract data types.

- We need data structures to organize a large amount of data and efficiently support application requirements.

- The best data structure depends on the application.

- For a data structure, there could be many operations, but the most basic and

  essential operations are insert, delete, and search.

- Hashing is a data structure in which the expected time of insert, delete, and search is $O(1)$, the best asymptotic time complexity you can achieve.

  - The worst case time complexity for the three operations is $O(n)$, where n is the number of elements.

### Hashing: Overview

- Suppose we have a one-dimensional array (or table): table[0:b-1].

- Each data element stored in this array is a dictionary pair (key, element).

- Each position of this array is called a bucket.

  -  A bucket can typically hold one dictionary pair.

  -  Sometimes a bucket has multiple slots, where each slot can hold a dictionary pair.

- In hashing, we have a hash function f that converts the key k into an index in the range [0, b-1].

- f(k) is called the home bucket for key k.
A dictionary pair (key, element) is stored in its home bucket table[f[key]].

![image](https://user-images.githubusercontent.com/46957634/135798649-5f523d15-91fa-471f-9338-d2fd04a2414d.png)

### Hashing: Example

- Suppose we have the following dictionary pairs. 
  - $(22, a), (33, c), (3, d), (71, e), (85, f)$

- Hash table is table[0:7], b = 8.

- Hash function is f(k) = k % 8. (remainder when k is divided by 8.)

- Pairs are stored in the table as below.

  ![image](https://user-images.githubusercontent.com/46957634/135798693-968f17ac-2c73-404b-a6a2-bf495a55f056.png)

- In this case, search, insert, delete takes $O(1) time.

  - We can just access the dictionary pair by hashing its key.

### Hashing: Collision and Overflow

- Suppose the state of our hashing table was like this.

  ![image](https://user-images.githubusercontent.com/46957634/135798797-8a335708-b433-4e24-87fd-b99cd893d159.png)

- We would like to insert a new dictionary pair, (27, g).

- Using our hash function, (27, g) should be inserted to table[3]. However, (3, d) is already occupying that bucket.

- Keys that have the same home bucket are called synonyms.
  - 3 and 27 are synonyms for the hash function we use.

- A collision occurs when the home bucket for a new pair is occupied by a pair with a different key.

- An overflow occurs when there is no space in the home bucket for the new pair.

- When a bucket can hold only one dictionary pair, a collision and an overflow occur together.
  - If a bucket has multiple slots, a collision may not lead to an overflow.

- We need a method to handle overflows.

  ![image](https://user-images.githubusercontent.com/46957634/135798834-166d844d-9d48-47f1-932b-e123fbb704e4.png)

### Hashing: Loading Density (Loading Factor)

- The loading density (or loading factor) α indicates how much the hash table is filled with dictionary pairs.

- α=n/(sb)

  -  n: number of dictionary pairs in the table.

  -  s: number of slots in a bucket

  -  b: number of buckets in the hash table.

- In the hash table below : b=8, s=1, n=5

- Its loading factor is 5 / 8 = 0.625 (62.5%).

- If the loading factor is high, we should consider increasing the size of hash table.

![image](https://user-images.githubusercontent.com/46957634/135798891-6d4418aa-d547-4da9-8452-b67f73a92fee.png)

### Issues in Hashing

- What hash function should we use?
- How should we handle overflow?
- What is the optimal size of a hash table?

### Hash Functions

- We use hashing because it is fast for searching elements in a hash table.
- Thus, the hash function should be easy to compute.
- Also, it should minimize the number of collisions.



- Minimizing number of collisions

  -  Suppose we have a key space where the keys are generated.- Example key space: [0:10000]

  -  If a key is generated randomly from the key space, we want the probability that h(k) = i to be 1/b for all buckets i.
     -  A random key has an equal chance of hashing into any buckets.

  -  A hash function that satisfies this property is called a uniform hashing function.

### Popular Hash Functions

- Division

  - One of the most widely used hash function.

  - h(k)=k%D
    - D is called divisor.
    - Since this function gives bucket address in the range 0 through D-1, b should be larger or equal to D.

- Choice of D
  - We can just set D equal to b, but sometimes other choices can be better.
  - For example, suppose the number of even keys is much larger than the number of odd keys in an application.
  - If D is even, odd keys are always mapped to odd buckets, and even keys are always mapped to even buckets.
  - Thus, using a even divisor will lead to biased selection of buckets.
  - If we use an odd divisor, this problem does not occur.

### Division: Example 

- Divisor = 5003

| Key Value | Address Value |
| --------- | ------------- |
| 123456789 | 2761          |
| 987654321 | 2085          |
| 000000472 | 0472          |
| 100064183 | 4813          |
| 200120472 | 0472          |

- Mid-Square
  - Square the key and then use an appropriate number of bits (digits) from the middle of the square to obtain the bucket address.
  - Example
    - key=4567
    - square = 4567 * 4567 = 20857489
    - bucket address = 57 (the middle two digits)
  - All digits of the original key contribute to the middle two digits of the squared value.
  - Thus, the result is not dominated by the distribution of the bottom digit or the top digit of the original key value.

- Folding
  - Key k is partitioned into several parts, all but possibly the last being of the same length.
  -  The partitions are then added together to obtain the hash address for k.

  - Example
    - k = 12320324111220
    - we partition it into parts that are three decimal digits long.
    - $P_1 =123,P_2 =203,P_3 =241,P_4 =112,P_5 =20$
    - If we use "shift folding", the bucket address is:
      -  $123+203+241+112+20=699$
    - If we use "folding at the boundaries", the bucket address is:
      -  $123+302+241+211+20=897$

- Digit Analysis
  - Each digit of the key is examined, and digits having the most balanced distribution are selected.
  - Useful when the keys (or pattern of the keys) are known a priori.

  - Example
    - keys: 012-452-0236, 012-153-0530, 015-342-0935, 012-752-1032, 012-852-0470
    - The first and the second digits are common to all keys -  not used
    - Duplicate digits appear in the the third key -  not used
    - The fourth digit is well distributed -  used
    - In the digits 5-7, many duplicates are seen -  not used
    - The eighth digit is well distributed -  used
    - The ninth digits have duplicates -  not used
    - For the tenth digit, two keys have duplicates, but still it is well distributed -  used.
    - Bucket addresses: 426, 150, 395, 702, 840.

### Hash Functions - Converting Keys to Integers

-  The keys are not always integers. It may be other types such as a string.

-  Suppose an application uses a 2 character string as the key in the dictionary pairs.

-  In the hash function, the key is first converted into a non-negative integer (of type int).

-  An int is represented using 4 bytes, whereas the key is 2 bytes.

-  In this case we can represent all keys uniquely, using the int.

-  The following code can be used to convert the keys.

```c
number = key[0];
number += ((int) key[1]) << 8;
```

- If the string key is longer than 4 characters, we cannot have a unique non-negative int representation.


- A function that converts a string into a nonnegative int.

```c
unsigned int stringToInt(char *key) {
  int number = 0;
  while(*key) {
    number += *key++;
    if(*key)
      number += ((int) *key++) << 8;
  }
  return number;
}
```

### Overflow Handling

- Even when an overflow occurs, we still need to store the dictionary pair.
- Two popular ways to handle overflows:
  - open addressing: if the home bucket is already full, search for a bucket that is not full yet.
    - linear probing
    - quadratic probing
    - rehashing
  - chaining: a bucket holds a list where all dictionary pairs addressed to the bucket are stored.

#### Open Addressing - Linear probing

- Suppose we would like to insert a dictionary pair whose key is k, into the hash table ht[].
-  We apply the hash function to get the bucket address h(k).
-  If the bucket ht[h(k)] is full, then we try the next bucket, ht[(h(k) + 1) % b].
-  If the bucket ht[(h(k) + 1) % b] is also full, then we try ht[(h(k) + 2) % b].
-  We search ht[(h(k)+i)%b], 0 ≤ i ≤ b-1.
-  If we find an unfilled bucket, we store the dictionary pair in that bucket.

##### Example

- Suppose we have the following string keys:
  - for, do, while, if, else, function

-  Our hash function does the following:
   -  We convert each character in the key string to its ASCII code.
   -  Then, we add the numbers to get the integer key.
   -  Then, we divide the key by 13 and its remainder is the bucket address.

- Bucket addresses for the keys
  - for:102+111+114=327,327%13=2
  - do:100+111=211,211%13=3
  - while:119+104+105+108+101=537,537%13=4
  - if:105+102=207,207%13=12
  - else:101+108+115+101=425,425%13=9
  - function:102+117+110+99+116+105+111+110=870,870%13=12

#### Linear probing: Example

- The dictionary pairs are stored in their home buckets.
-  When "function" is to be added, its home bucket [12] is already occupied by "if".
-  So we try the next bucket [0].
-  Since it is unfilled, we store "function" there.

#### Linear probing: Search

- Seaching should be done in a similar way
- We first compute h(k)
- Examine the hash table buckets in the order ht[h(k)], ht[(h(k)+1)%b], ..., ht[(h(k)+j)%b]
- If find the key, search is done.
- If we do not find the key and come back to ht[h(k)], the key is not in the table.

![image](https://user-images.githubusercontent.com/46957634/135811258-6531e151-a087-4a38-bbee-8c3f3ce8bd33.png)

#### Linear probing: another example

- The keys are lower-case strings.
- The hash function simply takes the first character of the keys and map to integers
  - a- 0,b- 1,c- 2,...,z- 25.
- We have a total of 26 buckets in the hash table.
- Suppose we have the following 11 keys:

- acos, atoi, char, define, exp, ceil, cos, float, atol, floor, ctime

- What is the number of buckets searched for each key?



#### Linear probing: another example

- acos, atoi, char, define, exp, ceil, cos, float, atol, floor, ctime
- acos is mapped to bucket 0. Since the bucket is empty, acos is stored there.
- atoi is mapped to bucket 0. Since the bucket is full, bucket 1 is checked. Since it is empty, atoi is stored there.
- char is stored in bucket 2.
- define is stored in bucket 3.
- exp is stored in bucket 4.
- ceil is mapped to bucket 2. Since buckets 2-4 are all full, ceil is stored in bucket 5. 4 bucket searches are needed.
- ctime is mapped to bucket 2. Since buckets 2-9 are all full, ctime is mapped to bucket 10. 9 bucket searches are needed until we find an unfilled bucket.

#### Other open addressing methods

##### Quadratic probing

- If ht[h(k)] is full, then we look at ht[(h(k) + i2) % b] and ht[(h(k) - i2) % b]. 
- We search for $1≤i≤\frac{(b-1)}2$.

##### Rehashing

- We prepare a series of hash functions h1, h2, ..., hm.
- Buckets are searched in the order hi(k), 1 ≤ i ≤ m.

### Overflow Handling: Chaining

- Linear probing can perform poorly, because search for a key involves comparison with keys with different hash values.
  - To search for ctime, we need to compare keys 9 times.

- In chaining, we maintain one list per bucket. The list contains all the synonyms for that bucket.
  - A list could be a simple linked list (chain), but it could also be a more complex data structure such as a tree.

#### Chaining: Example

- The keys are lower-case strings.
- The hash function simply takes the first character of the keys and map to integers
  - a- 0,b- 1,c- 2,...,z- 25.
- We have a total of 26 buckets in the hash table.
- We have the following 11 keys:
  - acos, atoi, char, define, exp, ceil, cos, float, atol, floor, ctime

- The dictionary pairs are stored as follows.


#### An implementation of chain search

```c
element* search(int k) {
  nodePointer current;
  int homeBucket = h(k);
  for(current = ht[homeBucket]; current; current = current->link) {
    if(current->data.key == k) 
      return &current->data;
  }
  return NULL;
}
```

### Performance Analysis

- Worst-case performance of hashing

  - insertion, search, deletion takes $O(n).

  -  consider the case where all keys are mapped to the same bucket.

- What is the expected performance?

  - Let ht[0:b-1] be a hash table with b buckets, each bucket having one slot.

  -  Let h be a uniform hash function with range [0, b-1].

  -  If n keys k1, k2, ..., kn are entered into the hash table, there are bn distinct hash sequences h(k1), h(k2), ..., h(kn). We assume that each sequence is equally likely to occur.

  -  Let Sn denote the average number of comparisons needed to find jth key kj, averaged over 1 ≤ j ≤ n.

  -  Let Un be the expected number of key comparisons when a search is made for a key not in the hash table.

#### Performance of hashing when chaining is used

- If the key being sought has h(k) = i, and chain i has q nodes on it, then q comparisons are needed if k is not on the chain.
- When the n keys are distributed uniformly over the b possible chains, the expected number in each chain is n/b = α.
- Since Un equals the expected number of keys on a chain, Un = α.
- When the ith key, ki, is being entered into the table, the expected number of keys on any chain is (i-1)/b. Hence, the expected number of comparisons needed to search for ki, after all n keys have been entered is 1 + (i-1)/b.

- Thus, $S_n = \frac{1}{n} {\Sigma_{i=1}^{n} {(1+\frac{i-1}{b})}} $ $=1+\frac{n-1}{2b} = 1 + \frac \alpha 2$

##### Performance of hashing when linear probing is used

- $U_n = \frac 1 2 (1+ \frac {1}{(1-\alpha)^2})$
- $S_n = \frac 1 2 (1+ \frac {1}{1-\alpha})$

